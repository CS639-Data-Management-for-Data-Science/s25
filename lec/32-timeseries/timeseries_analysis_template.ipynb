{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701eb825-7b07-4b8d-a395-25b01f56b585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install plotly\n",
    "!{sys.executable} -m pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbb7190-37fc-4f77-bfad-ce72237d92bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ab9956-1d5b-4a31-809b-7a21ea86160b",
   "metadata": {},
   "source": [
    "### Retailrocket recommender system dataset\n",
    "\n",
    "Source: https://www.kaggle.com/retailrocket/ecommerce-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f6d898-108e-46e4-8ea2-0628fc5375ea",
   "metadata": {},
   "source": [
    "Load the dataset files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcca2cd5-7f27-485d-80b7-68d1e24f4c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = pd.read_csv(os.path.join(\\\n",
    "    '..', 'timeseries_lec_data', 'events.csv'))\n",
    "item_properties = pd.read_csv(os.path.join(\\\n",
    "    '..', 'timeseries_lec_data', 'item_properties_part1.csv'))\n",
    "category_tree = pd.read_csv(os.path.join(\\\n",
    "    '..', 'timeseries_lec_data', 'category_tree.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fd0ab3-0f87-4cae-ae6a-28cf289498f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3deb63-562e-43cb-a981-aa74bf7405d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827fffa1-1b9d-4fb8-bb33-4eee8fc7302b",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ba1134-1cf4-4098-8c33-30dc01332461",
   "metadata": {},
   "outputs": [],
   "source": [
    "events['event_datetime'] = pd.to_datetime(events['timestamp'], unit='ms')\n",
    "events['event_date'] = events['event_datetime'].dt.date\n",
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d005e7-abf7-4202-8c93-126efc0bdda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_events = events.groupby(['event_date', 'itemid', 'event']).size().\\\n",
    "                                reset_index(name='event_count')\n",
    "grouped_events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15a601c-a5f0-4dee-837f-ee0b61c5f8c3",
   "metadata": {},
   "source": [
    "## Data imputation\n",
    "\n",
    "a process that replaces missing values in a dataset with substituted values\n",
    "\n",
    "### Other options for Data Imputation\n",
    "\n",
    "- Next or previous value\n",
    "- Maximum or Minimum Value\n",
    "- Statistical methods: mean, median, mode\n",
    "- Missing Value Prediction: using a machine learning model to determine the final imputation value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f89d87c-b6da-41c1-ba5e-5475824aa9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(639)\n",
    "\n",
    "date_range = pd.date_range(start='2024-01-01', periods=15, freq='D')\n",
    "sales_data = np.random.normal(loc=200, scale=20, size=len(date_range))\n",
    "sales_data[::5] = np.nan  # missing value every 5th day\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'date': date_range,\n",
    "    'sales': sales_data\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6840bcb6-b364-4219-af0b-6b78b55e2505",
   "metadata": {},
   "source": [
    "Replace with median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36093355-b33f-4d33-a130-e7663e274939",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'date': date_range,\n",
    "    'sales': sales_data\n",
    "})\n",
    "print(df)\n",
    "\n",
    "# df = #median\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8a15c3-7f60-437c-9ee4-8d41224fbb3f",
   "metadata": {},
   "source": [
    "Replace with mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbae908a-7cd6-4ed6-b2af-e09f3600ace8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(639)\n",
    "\n",
    "date_range = pd.date_range(start='2024-01-01', periods=15, freq='D')\n",
    "values = [100, 150, 200, 250]\n",
    "sales_data = np.random.choice(values, size=15).tolist()\n",
    "\n",
    "for i in range(0, len(sales_data), 5):\n",
    "    sales_data[i] = np.nan\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'date': date_range,\n",
    "    'sales': sales_data\n",
    "})\n",
    "print(df)\n",
    "\n",
    "df = #mode\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c706bcfc-6e7f-4013-9c10-0ccc26b57529",
   "metadata": {},
   "source": [
    "### Data Interpolation\n",
    "\n",
    "Interpolation is a technique that can be useful for handling missing values, particularly when the missing data is assumed to follow a pattern or trend based on the existing values in the dataset. This is often the case with time series or ordered data, where the missing values are assumed to lie between known values. Interpolation fills in these gaps by estimating the missing data points using existing values.\n",
    "\n",
    "When **NOT** to Use Interpolation:\n",
    "- Large gaps: If the data has large gaps between observations, interpolation might not provide meaningful or reliable estimates.\n",
    "- Randomness in missing values: If the missing values are random or don't follow any pattern (Missing Completely at Random - MCAR), interpolation may not be appropriate, as it assumes a relationship between values.\n",
    "- Categorical or non-numeric data: Interpolation is typically used for continuous numerical data. For categorical or binary data, interpolation is not suitable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bef1977-8ad7-40de-a63c-adbc976eaf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(639)\n",
    "\n",
    "date_range = pd.date_range(start='2024-01-01', periods=60, freq='D')\n",
    "sales_data = np.random.normal(loc=200, scale=20, size=len(date_range))\n",
    "sales_data[::5] = np.nan  # missing value every 5th day\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'date': date_range,\n",
    "    'sales': sales_data\n",
    "})\n",
    "print(df.head())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df['date'], df['sales'], marker='o', linestyle='-', color='black')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Sales')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9386a1-562c-4f20-ae96-fc35997579fb",
   "metadata": {},
   "source": [
    "### Linear interpolation\n",
    "\n",
    "- Assumption: the missing data points lie along a straight line between the known data points.\n",
    "- Linear interpolation commonly used for time series where changes are expected to be linear between data points.\n",
    "- When to use: when the relationship between consecutive values is roughly linear or changes gradually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978cd4a2-d6b2-4818-9129-0363f78dabc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear interpolation\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df['date'], df['sales'], marker='o', linestyle='-', \\\n",
    "         label='Interpolated Sales', color='orange')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5532cd76-8636-4993-923c-356a8c1ca9a3",
   "metadata": {},
   "source": [
    "### Polynomial interpolation\n",
    "\n",
    "- Polynomial interpolation fits a polynomial curve through the known data points and uses it to estimate the missing values.\n",
    "- When to use: when the data shows a nonlinear relationship between points (for example, seasonal effects or periodic patterns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fe5d67-1c9d-4cac-bd95-d53599961f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# polynomial interpolation\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df['date'], df['sales'], marker='o', linestyle='-', \\\n",
    "         label='Interpolated Sales', color='orange')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e891efb-3dcc-490e-9295-a71a8cdb6786",
   "metadata": {},
   "source": [
    "#### Why do both methods produced the same result?\n",
    "\n",
    "- Polynomial interpolation of order 2 fits a quadratic function (a parabola) between the two surrounding data points.\n",
    "- A quadratic function can curve, but for the simple case where the data points are relatively close to each other and do not exhibit any highly nonlinear or curving behavior, the quadratic curve might end up being very similar to the straight line in terms of interpolation.\n",
    "- When there are only two points surrounding the missing value (as is typical with simple time series data), the quadratic interpolation will essentially behave like a linear interpolation because a second-degree polynomial (a parabola) that passes through two points is uniquely determined by those two points and does not \"bend\" between them in a noticeable way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ffa4aa-14be-4bc9-8833-22ff2c49c157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-linear timeseries - sine curve\n",
    "np.random.seed(42)\n",
    "date_range = pd.date_range(start='2024-01-01', periods=60, freq='D')\n",
    "sales_data = 100 + 50 * np.sin(np.linspace(0, 3 * np.pi, len(date_range)))\n",
    "\n",
    "# Introduce missing values randomly\n",
    "missing_indices = np.random.choice(range(len(sales_data)), \\\n",
    "                                   size=18, replace=False)\n",
    "sales_data[missing_indices] = np.nan\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'date': date_range,\n",
    "    'sales': sales_data\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df['date'], df['sales'], marker='o', linestyle='-', \\\n",
    "         label='Original Sales with Missing Values', color='k')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Sales')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7994a6e-973f-4f2c-9f59-16b14734036d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate using linear method\n",
    "\n",
    "# Interpolate using polynomial method (order 2)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df['date'], df['sales_linear'], marker='o', linestyle='-', \\\n",
    "         label='Interpolated Sales (Linear)', color='orange')\n",
    "plt.plot(df['date'], df['sales_polynomial'], marker='x', linestyle='-', \\\n",
    "         label='Interpolated Sales (Polynomial)', color='green')\n",
    "plt.legend()\n",
    "plt.title('Linear vs Polynomial Interpolation on Nonlinear Data')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d0efd7-8dd7-4717-9e31-c33d825d1fff",
   "metadata": {},
   "source": [
    "### Spline interpolation\n",
    "\n",
    "- Spline interpolation fits a smooth curve (a piecewise polynomial, typically cubic) through the known data points and estimates the missing values.\n",
    "- When to use: when the data exhibits a smooth, nonlinear trend (often used for time series with cycles or seasonal patterns).\n",
    "\n",
    "### Spline vs Polynomial\n",
    "\n",
    "- When to use spline interpolation: when you need smooth, piecewise fits, especially when the data is non-linear or has noise. It's ideal for smooth, continuous data that needs to be modeled accurately across a range of values.\n",
    "- When to use polynomial interpolation: when you have a simple, small dataset, and you want a single polynomial that fits all points exactly. Avoid polynomial interpolation with large or noisy datasets because it can cause overfitting and oscillations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d059ec1f-1a24-4bbb-b4a8-0a6928422682",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(639)\n",
    "date_range = pd.date_range(start='2024-01-01', periods=60, freq='D')\n",
    "sales_data = 100 * np.sin(np.linspace(0, 3 * np.pi, len(date_range))) \n",
    "\n",
    "# Introduce missing values randomly\n",
    "missing_indices = np.random.choice(range(5, len(sales_data), 5), \\\n",
    "                                   size=10, replace=False)\n",
    "sales_data[missing_indices] = np.nan\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'date': date_range,\n",
    "    'sales': sales_data\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df['date'], df['sales'], marker='o', linestyle='-', \\\n",
    "         label='Original Sales with Missing Values', color='blue')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Sales')\n",
    "plt.grid(True)\n",
    "\n",
    "# Interpolate using cubic spline method\n",
    "\n",
    "\n",
    "plt.plot(df['date'], df['sales_spline'], marker='x', linestyle='-', \\\n",
    "         label='Interpolated Sales (Spline)', color='green')\n",
    "plt.legend()\n",
    "plt.title('Spline Interpolation on Sinusoidal Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0d9540-d463-4923-b06d-d403990f394f",
   "metadata": {},
   "source": [
    "### Retailrocket recommender system dataset analysis\n",
    "\n",
    "#### Q1: Calculate the count of each unique property corresponding to \"addtocart\" items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5c779d-bf70-4fb1-9f2d-b8b6be2b1867",
   "metadata": {},
   "outputs": [],
   "source": [
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7808ef-ef4a-4820-8f17-176cdfde5bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe5ad8b-125f-4ecf-82bf-693c6951d827",
   "metadata": {},
   "outputs": [],
   "source": [
    "addtocart_events = \n",
    "addtocart_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7345dab8-470b-4ca2-952a-38382e2d938e",
   "metadata": {},
   "outputs": [],
   "source": [
    "addtocart_events = events[events['event'] == 'addtocart']\n",
    "merged_data = # left join\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4082e1f6-2f71-45a1-88ff-3241550c8262",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_counts = \n",
    "print(property_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b98e646-e9c0-4b6c-80c9-67824f3c2aff",
   "metadata": {},
   "source": [
    "### Correlation Methods\n",
    "\n",
    "In EDA, various correlation methods are used to understand the relationship between numerical variables. \n",
    "\n",
    "#### What is correlation? \n",
    "\n",
    "The variables are said to be correlated if the changes in one variable results in a corresponding change in another variable.\n",
    "\n",
    "#### Pearson correlation (Linear relationship)\n",
    "\n",
    "Pearson correlation coefficientmeasures the strength of a relationship between two variables and their association with one another (linear correlation).\n",
    "\n",
    "#### Spearman correlation (Monotonic relationship)\n",
    "\n",
    "Spearman correlation enables us to assess the monotonic relationship between between two ranked variables. That is, how well the relationship between two variables could be represented using a monotonic function.\n",
    "\n",
    "- The Spearman Rank Correlation can take a value from +1 to -1 where:\n",
    "    - +1 means a perfect association\n",
    "    - 0 means that there is no association\n",
    "    - -1 means a perfect negative association\n",
    "- Further description of the correlation\n",
    "    - .00-.19 \"very weak\"\n",
    "    - .20-.39 \"weak\"\n",
    "    - .40-.59 \"moderate\"\n",
    "    - .60-.79 \"strong\"\n",
    "    - .80-1.0 \"very strong\"\n",
    "\n",
    "#### Kendall's Tau correlation\n",
    "Kendall's tau is a measure of the correspondence between two rankings\n",
    "\n",
    "#### Which correlation type should you choose?\n",
    "\n",
    "- Use Pearson for linear relationships when data assumptions are met.\n",
    "- Use Spearman for ordinal data or when data isn't linear.\n",
    "- Use Kendall's Tau for smaller datasets and many rank ties\n",
    "\n",
    "#### Readings:\n",
    "\n",
    "1. https://www.simplilearn.com/tutorials/statistics-tutorial/spearmans-rank-correlation#:~:text=Spearman's%20rank%20correlation%20measures%20the,represented%20using%20a%20monotonic%20function. \n",
    "2. https://www.simplilearn.com/tutorials/statistics-tutorial/pearson-correlation-coefficient-in-statistics#pearsons_correlation_coefficient\n",
    "3. https://datatab.net/tutorial/pearson-correlation\n",
    "4. https://datatab.net/tutorial/spearman-correlation\n",
    "5. https://datatab.net/tutorial/dispersion-parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f992fa1a-e3cf-4575-a08b-f88a87d4a7f4",
   "metadata": {},
   "source": [
    "#### Q2: What is the Spearman correlation between the number of \"view\" events and the number of \"addtocart\" events per item?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511d0115-56f4-4798-b728-c0cd684d8221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter 'view' and 'addtocart' events\n",
    "view_events = \n",
    "addtocart_events = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5003f4-f645-4d89-a95c-b2264c4a6b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item count\n",
    "view_counts =\n",
    "addtocart_counts = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2607b63-0086-49ce-b45d-602ff0db6701",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_df = \n",
    "addtocart_df = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db43961d-f262-4d51-8d71-e64df330577e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8045e138-5baf-4055-b4c4-6991774516ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_corr = \n",
    "spearman_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b03989-1d8d-4264-be34-14952acc3bdf",
   "metadata": {},
   "source": [
    "#### Q3: What is the Pearson correlation between the number of \"view\" events and the number of \"addtocart\" events per item?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5621b346-f6e2-4523-beba-86fd061fa5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_corr = merged_df['view_count'].corr(merged_df['addtocart_count'], \\\n",
    "                                            method='??')\n",
    "pearson_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8badf06-dea9-4672-9851-79440d627c9d",
   "metadata": {},
   "source": [
    "#### Q4: What is the Kendall's Tau correlation between the number of \"view\" events and the number of \"addtocart\" events per item?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a2e88a-8c57-4338-84c5-bcaea5f08696",
   "metadata": {},
   "outputs": [],
   "source": [
    "kendall_tau_corr = merged_df['view_count'].corr(merged_df['addtocart_count'], \\\n",
    "                                                method='??')\n",
    "kendall_tau_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0b38a0-6193-40b9-9206-e01d6dd9e6ce",
   "metadata": {},
   "source": [
    "#### Q5: Create a scatter plot with ordinary least squares' trend line to show correlation between the number of \"view\" events and the number of \"addtocart\" events per item. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed20d0ed-e833-4318-b4aa-a8bebdac2fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig.write_html('scatter_plot_with_ols_trendline.html')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1c6431-452f-48bc-92f6-d1c39502ee2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16be9022-1ae1-44e3-ac82-92f7d687bcc0",
   "metadata": {},
   "source": [
    "#### Q6: Plot a line chart of the number of events (view, transaction, etc.) over time, color-coded by the event type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af8339f-41d4-40c5-95b6-59ea6d115bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_grouped = \n",
    "\n",
    "fig.write_html('events_vs_date.html')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca78d27-08e1-4f8e-9aca-18f93c83ded9",
   "metadata": {},
   "source": [
    "#### pandas `resample` method\n",
    "\n",
    "Documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9908a3-513c-49c9-ad00-c5a471d362da",
   "metadata": {},
   "source": [
    "#### Q7: Calculate the monthly count number of events and create a line chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc06e9f5-b3df-4095-ab2f-2bbb302c7d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set timestamp as the index, resample to Month-Start, and calculate the count of number of events\n",
    "monthly_avg = \n",
    "\n",
    "# fig = px.line(\n",
    "#     monthly_avg, \n",
    "#     x='event_datetime', \n",
    "#     y='event_count', \n",
    "#     color='year', \n",
    "#     title=\"Monthly total event counts\",\n",
    "#     labels={'event_datetime': 'Month', 'event_count': 'Average Events', 'year': 'Year'}\n",
    "# )\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7998f2b-4acc-4f8b-a51e-a8273123e663",
   "metadata": {},
   "source": [
    "#### Q8: Calculate the total number of events per day of the week for each year and visualize the trend with a line chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c207985-0040-4dad-a1bc-a954fc5c50d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_v2 = events.copy()\n",
    "\n",
    "events_v2['year'] = \n",
    "events_v2['dayofweek'] = \n",
    "                        # Add 1 to make Monday = 1, Sunday = 7\n",
    "\n",
    "events_v2 = \n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1106e0e5-8d3f-44e8-81e2-bba11352f719",
   "metadata": {},
   "outputs": [],
   "source": [
    "events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f641cbe-1be6-4ce0-877b-f7f30a11fa90",
   "metadata": {},
   "source": [
    "#### Q9: Aggregate the number of events per day and plot the trend for the total number of events over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaf9e39-5629-47ca-9d6f-caef1eb452df",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_per_day = \n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7e6650-1485-48fe-877f-6065e6b9e2ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
